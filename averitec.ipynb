{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnlmkNJhC6LG",
        "outputId": "37fe80f4-a165-426e-97bd-30714d779511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines) (25.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: rank_bm25, jsonlines\n",
            "Successfully installed jsonlines-4.0.0 rank_bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn nltk rank_bm25 jsonlines"
      ]
    },
    {
      "source": [
        "import jsonlines\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load JSONL Data\n",
        "def load_data(file_path):\n",
        "    data = []\n",
        "    try:\n",
        "        with jsonlines.open(file_path) as reader:\n",
        "            for obj in reader:\n",
        "                data.append(obj)\n",
        "    except jsonlines.InvalidLineError as e:\n",
        "        print(f\"Error parsing JSONL file: {e}\")\n",
        "        # Print the problematic line for debugging:\n",
        "        print(f\"Problematic line: {e.line}\")\n",
        "        # If you know the error, you can add logic to fix it here.\n",
        "        # For example, if it's a missing comma, you could try to insert it.\n",
        "        return pd.DataFrame([])  # Return empty DataFrame in case of error\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Load Train & Test Data\n",
        "train_df = load_data(\"train.json\")\n",
        "test_df = load_data(\"test.json\")\n",
        "\n",
        "# Check data structure\n",
        "print(train_df.head())"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bolp382YDv0_",
        "outputId": "2c052ac5-141a-42be-fe80-371d88bdfd29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error parsing JSONL file: line contains invalid json: unexpected end of data: line 2 column 1 (char 2) (line 1)\n",
            "Problematic line: [\n",
            "Error parsing JSONL file: line contains invalid json: unexpected end of data: line 2 column 1 (char 2) (line 1)\n",
            "Problematic line: [\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXq8e1_GGNbA",
        "outputId": "7fbb5bd4-cb75-4e38-d767-742d228cd59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load JSON file into DataFrame\n",
        "df = pd.read_json(\"train.json\")\n",
        "\n",
        "# Display DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD2ozLt8GO5w",
        "outputId": "7b61c87b-0edc-4396-ff9f-9c2bcfe5858b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               claim  required_reannotation  \\\n",
            "0  Hunter Biden had no experience in Ukraine or i...                  False   \n",
            "1  Donald Trump delivered the largest tax cuts in...                  False   \n",
            "2  In Nigeria … in terms of revenue share, 20% go...                  False   \n",
            "3  Biden has pledged to stop border wall construc...                  False   \n",
            "4  After the police shooting of Jacob Blake, Gov....                  False   \n",
            "\n",
            "       label                                      justification claim_date  \\\n",
            "0  Supported                       No former experience stated.  25-8-2020   \n",
            "1    Refuted  Three tax bills have been larger than that of ...  25-8-2020   \n",
            "2  Supported  The answer and source shows that the claim is ...  25-8-2020   \n",
            "3  Supported  This claim should have been split into two par...  25-8-2020   \n",
            "4    Refuted  Governor Evers did call for peace in a video s...  25-8-2020   \n",
            "\n",
            "                   speaker                                 original_claim_url  \\\n",
            "0                Pam Bondi                                               None   \n",
            "1               Eric Trump                                               None   \n",
            "2             Raila Odinga        https://www.youtube.com/watch?v=w5x3rmkrDOE   \n",
            "3               Eric Trump                                               None   \n",
            "4  Senator Howard Marklein  https://www.facebook.com/SenMarklein/posts/166...   \n",
            "\n",
            "                               fact_checking_article  \\\n",
            "0  https://web.archive.org/web/20210111003633/htt...   \n",
            "1  https://web.archive.org/web/20210111003633/htt...   \n",
            "2  https://web.archive.org/web/20210307003741/htt...   \n",
            "3  https://web.archive.org/web/20210111003633/htt...   \n",
            "4  https://web.archive.org/web/20210428162642/htt...   \n",
            "\n",
            "                               reporting_source location_ISO_code  \\\n",
            "0  Speech at The Republican National Convention                US   \n",
            "1  Speech at The Republican National Convention                US   \n",
            "2                                       YouTube                KE   \n",
            "3  Speech at The Republican National Convention                US   \n",
            "4                                      Facebook                US   \n",
            "\n",
            "              claim_types                  fact_checking_strategies  \\\n",
            "0    [Position Statement]                        [Written Evidence]   \n",
            "1       [Numerical Claim]  [Written Evidence, Numerical Comparison]   \n",
            "2       [Numerical Claim]                  [Fact-checker Reference]   \n",
            "3    [Position Statement]                        [Written Evidence]   \n",
            "4  [Event/Property Claim]                        [Written Evidence]   \n",
            "\n",
            "                                           questions  \\\n",
            "0  [{'question': 'Did Hunter Biden have any exper...   \n",
            "1  [{'question': 'Did the 2017 tax bill deliver t...   \n",
            "2  [{'question': 'Kenya’s ex-prime minister Oding...   \n",
            "3  [{'question': 'When Joe Biden participated in ...   \n",
            "4  [{'question': 'Did Governor Evers not call for...   \n",
            "\n",
            "                           cached_original_claim_url  \n",
            "0                                               None  \n",
            "1                                               None  \n",
            "2  https://web.archive.org/web/20230420095918/htt...  \n",
            "3                                               None  \n",
            "4  https://web.archive.org/web/20230420103547/htt...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load JSON file into DataFrame\n",
        "df = pd.read_json(\"test.json\")\n",
        "\n",
        "# Display DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeBT80cBLeZt",
        "outputId": "49e0afee-aed5-4882-ea3f-dc6dad786f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               claim  claim_id  claim_date  \\\n",
            "0  Every Democrat on the Energy and Commerce Comm...         0  22-12-2021   \n",
            "1  Meat packing workers have suffered more COVID-...         1   3-12-2021   \n",
            "2  South African hospital found that traces of th...         2   3-12-2021   \n",
            "3  Pfizer is “managed by Black Rock (sic) finance...         3   2-12-2021   \n",
            "4  The Chinese biological laboratory in Wuhan is ...         4   2-12-2021   \n",
            "\n",
            "           speaker                                 original_claim_url  \\\n",
            "0   LAUREN GIELLA   https://web.archive.org/web/20210623232457/htt...   \n",
            "1  Bruce Blackburn                                               None   \n",
            "2             None                                               None   \n",
            "3      Susan Mundy    https://archive.ph/TkAYD#selection-346.0-767.42   \n",
            "4      Susan Mundy    https://archive.ph/TkAYD#selection-346.0-767.42   \n",
            "\n",
            "  reporting_source location_ISO_code  \n",
            "0          twitter                US  \n",
            "1         Facebook                US  \n",
            "2         Facebook                ZA  \n",
            "3         facebook              None  \n",
            "4         facebook              None  \n"
          ]
        }
      ]
    },
    {
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Download the missing punkt_tab data\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "# Text Cleaning Function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'\\W+', ' ', text)  # Remove special characters\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    tokens = word_tokenize(text)  # Tokenization\n",
        "    tokens = [word for word in tokens if word not in STOPWORDS]  # Remove stopwords\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply Preprocessing\n",
        "df[\"clean_claim\"] = df[\"claim\"].apply(preprocess_text)\n",
        "print(df.head())"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJLZZ8rYMUqY",
        "outputId": "a778ad32-37ad-411c-93a4-ccdb5ca6201b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               claim  claim_id  claim_date  \\\n",
            "0  Every Democrat on the Energy and Commerce Comm...         0  22-12-2021   \n",
            "1  Meat packing workers have suffered more COVID-...         1   3-12-2021   \n",
            "2  South African hospital found that traces of th...         2   3-12-2021   \n",
            "3  Pfizer is “managed by Black Rock (sic) finance...         3   2-12-2021   \n",
            "4  The Chinese biological laboratory in Wuhan is ...         4   2-12-2021   \n",
            "\n",
            "           speaker                                 original_claim_url  \\\n",
            "0   LAUREN GIELLA   https://web.archive.org/web/20210623232457/htt...   \n",
            "1  Bruce Blackburn                                               None   \n",
            "2             None                                               None   \n",
            "3      Susan Mundy    https://archive.ph/TkAYD#selection-346.0-767.42   \n",
            "4      Susan Mundy    https://archive.ph/TkAYD#selection-346.0-767.42   \n",
            "\n",
            "  reporting_source location_ISO_code  \\\n",
            "0          twitter                US   \n",
            "1         Facebook                US   \n",
            "2         Facebook                ZA   \n",
            "3         facebook              None   \n",
            "4         facebook              None   \n",
            "\n",
            "                                         clean_claim  \n",
            "0  every democrat energy commerce committee block...  \n",
            "1  meat packing workers suffered covid 19 cases h...  \n",
            "2  south african hospital found traces novel coro...  \n",
            "3  pfizer managed black rock sic finances chance ...  \n",
            "4  chinese biological laboratory wuhan owned glax...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Transform the claim text into numerical vectors\n",
        "X = vectorizer.fit_transform(df[\"clean_claim\"])\n",
        "\n",
        "# Convert labels into numerical values\n",
        "label_map = {\"Supported\": 0, \"Refuted\": 1, \"Not Enough Evidence\": 2, \"Conflicting Evidence/Cherry-picking\": 3}\n",
        "df[\"label_encoded\"] = df[\"label\"].map(label_map)\n",
        "\n",
        "# Display shape of the dataset\n",
        "print(f\"Feature Matrix Shape: {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "h8BGX7XqMY7n",
        "outputId": "d28acc87-2aed-49f8-94c2-9812320de280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'label'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d4175d0e34ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Convert labels into numerical values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Supported\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Refuted\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Not Enough Evidence\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Conflicting Evidence/Cherry-picking\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_encoded\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Display shape of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZCeZwL7Mzlj",
        "outputId": "3a9b5cc9-074c-4948-e6fb-bdbc300ab85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['claim', 'claim_id', 'claim_date', 'speaker', 'original_claim_url',\n",
            "       'reporting_source', 'location_ISO_code', 'clean_claim'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load the JSON file and print an example entry\n",
        "with open(\"train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Print the first entry\n",
        "print(data[0].keys())  # This will show all available keys in the dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3wp9kpsM-DU",
        "outputId": "3712a603-943b-4778-e971-a7cdf272d57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['claim', 'required_reannotation', 'label', 'justification', 'claim_date', 'speaker', 'original_claim_url', 'fact_checking_article', 'reporting_source', 'location_ISO_code', 'claim_types', 'fact_checking_strategies', 'questions', 'cached_original_claim_url'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load JSON file\n",
        "with open(\"train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)  # Load full JSON list\n",
        "\n",
        "# Convert JSON list to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Check if \"label\" is now included\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc3zBJESOki0",
        "outputId": "18ca7233-cae7-4cf5-8c7a-47631e798e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['claim', 'required_reannotation', 'label', 'justification',\n",
            "       'claim_date', 'speaker', 'original_claim_url', 'fact_checking_article',\n",
            "       'reporting_source', 'location_ISO_code', 'claim_types',\n",
            "       'fact_checking_strategies', 'questions', 'cached_original_claim_url'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Download the missing punkt_tab data\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "# Text Cleaning Function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'\\W+', ' ', text)  # Remove special characters\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    tokens = word_tokenize(text)  # Tokenization\n",
        "    tokens = [word for word in tokens if word not in STOPWORDS]  # Remove stopwords\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply Preprocessing\n",
        "df[\"clean_claim\"] = df[\"claim\"].apply(preprocess_text)\n",
        "\n",
        "\n",
        "# Convert labels into numerical values, handling unknown labels\n",
        "label_map = {\"Supported\": 0, \"Refuted\": 1, \"Not Enough Evidence\": 2, \"Conflicting Evidence/Cherry-picking\": 3}\n",
        "# If a label is not found in label_map, it will be assigned -1 or any other suitable value\n",
        "df[\"label_encoded\"] = df[\"label\"].map(label_map).fillna(-1).astype(int)\n",
        "#fillna replaces NaN with -1. astype(int) converts to integers.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vicA5KXaOsx3",
        "outputId": "36cb7999-d33e-479e-c489-4ef8293e09a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Transform the claim text into numerical vectors\n",
        "X = vectorizer.fit_transform(df[\"clean_claim\"])\n",
        "\n",
        "# Convert labels into numerical values\n",
        "label_map = {\"Supported\": 0, \"Refuted\": 1, \"Not Enough Evidence\": 2, \"Conflicting Evidence/Cherry-picking\": 3}\n",
        "df[\"label_encoded\"] = df[\"label\"].map(label_map)\n",
        "\n",
        "# Display shape of the dataset\n",
        "print(f\"Feature Matrix Shape: {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB0YCFEVOuJH",
        "outputId": "ae8aee57-f1fd-4bcf-934e-9fc686e1d219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Matrix Shape: (3068, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"label\"].isna().sum())  # Count NaN values in label column\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnFwD52gPW6b",
        "outputId": "53eb088d-6cdd-4561-c039-30371c3b4058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=[\"label\"])\n"
      ],
      "metadata": {
        "id": "sy0mQWE1PxA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label\"].fillna(\"Not Enough Evidence\", inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAQiWJjqP2xJ",
        "outputId": "59a8f031-91a3-449c-a067-be9737ef74a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-3c7f571bbd70>:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"label\"].fillna(\"Not Enough Evidence\", inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NaN values in label column:\", df[\"label\"].isna().sum())  # Check NaNs in the original label column\n",
        "print(\"NaN values in label_encoded column:\", df[\"label_encoded\"].isna().sum())  # Check NaNs in the encoded label column\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf99wxycQDbP",
        "outputId": "bda0b4f3-a4a7-4bf1-9b9e-1fc907ed2274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values in label column: 0\n",
            "NaN values in label_encoded column: 195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find unique labels in the dataset\n",
        "print(\"Unique labels in dataset:\", df[\"label\"].unique())\n",
        "\n",
        "# Find labels that were not mapped correctly\n",
        "unmapped_labels = df[df[\"label_encoded\"].isna()][\"label\"].unique()\n",
        "print(\"Labels that caused NaN in encoding:\", unmapped_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjhqYYPYQMxp",
        "outputId": "4e630b27-1833-4ca1-a0d4-779368d584be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in dataset: ['Supported' 'Refuted' 'Conflicting Evidence/Cherrypicking'\n",
            " 'Not Enough Evidence']\n",
            "Labels that caused NaN in encoding: ['Conflicting Evidence/Cherrypicking']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    \"Supported\": 0,\n",
        "    \"Refuted\": 1,\n",
        "    \"Not Enough Evidence\": 2,\n",
        "    \"Conflicting Evidence/Cherry-picking\": 3\n",
        "}\n",
        "\n",
        "# If there are variations in spelling, add them to the map\n",
        "df[\"label_encoded\"] = df[\"label\"].map(label_map)\n",
        "\n",
        "# Fill remaining NaN labels with \"Not Enough Evidence\" (default class)\n",
        "df[\"label_encoded\"].fillna(2, inplace=True)  # Assign 2 = \"Not Enough Evidence\"\n",
        "\n",
        "# Convert to integer\n",
        "df[\"label_encoded\"] = df[\"label_encoded\"].astype(int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kohzw75mQPj1",
        "outputId": "4475be76-aa92-41ea-b889-42c37074060c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-740c3218c58f>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"label_encoded\"].fillna(2, inplace=True)  # Assign 2 = \"Not Enough Evidence\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NaN values in label_encoded after fixing:\", df[\"label_encoded\"].isna().sum())  # Should be 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28lJlwrcQXma",
        "outputId": "53a31c95-f196-43cc-8687-9f202e27ac9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values in label_encoded after fixing: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df[\"label_encoded\"], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Model\n",
        "clf = LogisticRegression(max_iter=500)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Model Evaluation\n",
        "print(\"Model Evaluation:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7eN2AyuQZRc",
        "outputId": "65d1556f-b122-4f4e-f3df-280728bdd79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.40      0.51       167\n",
            "           1       0.66      0.95      0.78       359\n",
            "           2       0.40      0.02      0.04        88\n",
            "\n",
            "    accuracy                           0.67       614\n",
            "   macro avg       0.59      0.46      0.44       614\n",
            "weighted avg       0.64      0.67      0.60       614\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# Tokenize evidence text\n",
        "df[\"tokenized_evidence\"] = df[\"evidence\"].apply(lambda x: nltk.word_tokenize(str(x).lower()))\n",
        "\n",
        "# Initialize BM25 Model\n",
        "bm25 = BM25Okapi(df[\"tokenized_evidence\"])\n",
        "\n",
        "# Function to Retrieve Best Evidence for a Claim\n",
        "def retrieve_best_evidence(claim):\n",
        "    tokenized_claim = nltk.word_tokenize(claim.lower())\n",
        "    scores = bm25.get_scores(tokenized_claim)\n",
        "    best_evidence_idx = scores.argmax()\n",
        "    return df.iloc[best_evidence_idx][\"evidence\"]fg,ktdiu8rex7w4z\n",
        "\n",
        "# Apply evidence retrieval to test set\n",
        "df[\"retrieved_evidence\"] = df[\"clean_claim\"].apply(retrieve_best_evidence)\n",
        "\n",
        "print(\"Evidence Retrieval Completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "HFMBJsgrQl-K",
        "outputId": "1660e429-9622-4bfc-8b28-2fdda366122a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'evidence'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'evidence'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-941b529beb47>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Tokenize evidence text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokenized_evidence\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"evidence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Initialize BM25 Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'evidence'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ev2r score\n"
      ],
      "metadata": {
        "id": "Fbxa8e4JTLD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict labels using trained Logistic Regression model\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Convert numerical predictions back to label names\n",
        "reverse_label_map = {0: \"Supported\", 1: \"Refuted\", 2: \"Not Enough Evidence\", 3: \"Conflicting Evidence/Cherry-picking\"}\n",
        "df_test[\"predicted_label\"] = [reverse_label_map[p] for p in y_pred]\n",
        "\n",
        "# Check structure\n",
        "print(df_test[[\"claim\", \"predicted_label\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "qgN9coMKTNBq",
        "outputId": "b688cc98-b48f-4884-f513-3a8b9d5d4463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-bfd17fade718>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Convert numerical predictions back to label names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreverse_label_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Supported\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Refuted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Not Enough Evidence\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Conflicting Evidence/Cherry-picking\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predicted_label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreverse_label_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Check structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, df[\"label_encoded\"], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "NNMXkAU3TbUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df.iloc[y_test.index]  # Use y_test.index instead of X_test.index\n"
      ],
      "metadata": {
        "id": "zzOlRs1wTcNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert numerical predictions back to text labels\n",
        "reverse_label_map = {0: \"Supported\", 1: \"Refuted\", 2: \"Not Enough Evidence\", 3: \"Conflicting Evidence/Cherry-picking\"}\n",
        "\n",
        "# Assign predicted labels\n",
        "df_test[\"predicted_label\"] = [reverse_label_map[p] for p in y_pred]\n",
        "\n",
        "# Check structure\n",
        "print(df_test[[\"claim\", \"predicted_label\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh4BgzlVTmA0",
        "outputId": "5880ec58-90d6-455d-ddeb-1f1938050821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  claim predicted_label\n",
            "2650  South Africa has launched a Youth Employment S...       Supported\n",
            "1739  A Muslim man in India was killed by a mob afte...         Refuted\n",
            "2605  The number of people on health insurance in Ke...       Supported\n",
            "1455  The ExIm Bank provided taxpayer-backed handout...         Refuted\n",
            "2163  £22 billion was taken out of welfare spending ...         Refuted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-47f92c07fb20>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test[\"predicted_label\"] = [reverse_label_map[p] for p in y_pred]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that retrieved and reference evidence exist\n",
        "print(df_test[[\"retrieved_evidence\", \"reference_evidence\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "eS022HuPTovY",
        "outputId": "0f2f2fc2-0446-449a-ddb0-22fd2ada259b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['retrieved_evidence', 'reference_evidence'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-27a69b0cb5a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Verify that retrieved and reference evidence exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"retrieved_evidence\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reference_evidence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['retrieved_evidence', 'reference_evidence'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    }
  ]
}